# BertTokenizer4D

A Delphi implementation of the BERT tokenizer ‚Äî `TBertTokenizer` ‚Äî inspired by the .NET [`FastBertTokenizer`](https://github.com/georg-jung/FastBertTokenizer). It supports WordPiece tokenization and converts text into token ID sequences ready for input into BERT models via ONNX.

## üì¶ Features

* Load vocabulary from file (`vocab.txt`) or stream
* Load tokenizer configuration from Hugging Face (`tokenizer.json`)
* Converts raw text into token ID arrays
* Decodes token IDs back into readable text
* Compatible with [TONNXRuntime](https://github.com/hshatti/TONNXRuntime) for ONNX inference

## üìÅ Project Structure

* Main unit: `Src/BertTokenizer/BertTokenizer.pas`
* Core class: `TBertTokenizer`

## üöÄ Quick Start

```pascal
uses
  BertTokenizer, BertTokenizer.Extensions;

procedure LoadTokenizerAndEncode(const APath: string);
begin
  var Tokenizer := TBertTokenizer.Create;
  try 
    Tokenizer.LoadFromHuggingFace('bge-micro-v2');
    var Tokens := Tokenizer.Encode('Hello, world!');
    // TokenIds can now be passed to a model using TONNXRuntime
  finally
    Tokenizer.Free;
  end;
end;
```

## üß† Public API

| Method                                  | Description                                            |
| --------------------------------------- | ------------------------------------------------------ |
| `LoadVocabulary(FileName, ...)`         | Loads vocabulary from a `vocab.txt` file               |
| `LoadVocabularyFromStream(Stream, ...)` | Loads vocabulary from a stream                         |
| `LoadTokenizerJson(FileName)`           | Loads tokenizer from a Hugging Face `tokenizer.json`   |
| `LoadTokenizerJsonFromStream(Stream)`   | Loads tokenizer from a JSON stream                     |
| `Encode(Text)`                          | Tokenizes input text and returns an array of token IDs |
| `Decode(Tokens)`                        | Decodes an array of token IDs back to text             |
| --------------------------------------- | ------------------------------------------------------ |
| uses BertTokenizer.Extensions           |                                                        |
| `LoadFromHuggingFace(HuggingFaceRepo)`  | Loads tokenizer from Hugging Face repo by name         |

### ‚úÖ Supported Tokenizer Formats

* **`vocab.txt`** ‚Äî standard BERT vocabulary file
* **`tokenizer.json`** ‚Äî Hugging Face tokenizer format (WordPiece-based)

## ‚úÖ Dependencies

* **Delphi 10.2 Tokyo+**
* No external dependencies required for core functionality
* Optional test suite using [`DUnitX`](https://github.com/VSoftTechnologies/DUnitX)

### üß™ Test Coverage

This project includes unit tests using `DUnitX`.

## ü§ñ BERT + ONNX Integration

The output of `Encode` is compatible with ONNX BERT models. You can use [`TONNXRuntime`](https://github.com/hshatti/TONNXRuntime) to run inference on tokenized input (`input_ids`).

## üìÑ License

MIT License ‚Äî free to use, modify, and distribute.
